#!/usr/bin/env python3
# analyze_scripts.py
# åŠŸèƒ½ï¼šæƒææ‰€æœ‰ .py èˆ‡ .sh æª”æ¡ˆï¼Œè£œä¸Šç¼ºå¤±è¨»è§£ä¸¦è¼¸å‡º Markdown èˆ‡ JSON æ¸…å–®
# ç”¨é€”ï¼šé›†ä¸­ç®¡ç†è…³æœ¬æè¿°èˆ‡ç”¨é€”ï¼Œè¼”åŠ©ç¶­è­·èˆ‡æŸ¥é–±

import os
import json
from pathlib import Path

def normalize_comments(lines: list[str], total=3):
    """è£œé½Šè¨»è§£è¡Œæ•¸è‡³ total"""
    while len(lines) < total:
        lines.append("")
    return lines[:total]

def extract_header(file_path: Path):
    try:
        lines = file_path.read_text(encoding="utf-8").splitlines()

    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è®€å– {file_path}: {e}")
        return None

    suffix = file_path.suffix
    filename = file_path.name

    comment_lines = []
    updated = False

    if suffix == ".py":
        # å–å‰3è¡Œä¸­æœ‰ # çš„éƒ¨åˆ†
        for line in lines[:3]:
            if line.strip().startswith("#"):
                comment_lines.append(line.strip("# ").strip())
        comment_lines = normalize_comments(comment_lines)
        lang = "python"

    elif suffix == ".sh":
        lang = "bash"
        header_region = lines[1:5] if lines and lines[0].startswith("#!") else lines[:4]
        for line in header_region:
            if line.strip().startswith("#"):
                comment_lines.append(line.strip("# ").strip())
        if len(comment_lines) < 3:
            print(f"ğŸ› ï¸  è£œä¸Šè¨»è§£ï¼š{filename}")
            shebang = lines[0] if lines and lines[0].startswith("#!") else "#!/bin/bash"
            new_header = [
                f"# {filename}",
                "# åŠŸèƒ½ï¼šè«‹è£œä¸Šè…³æœ¬çš„åŠŸèƒ½èªªæ˜",
                "# ç”¨é€”ï¼šè«‹è£œä¸Šè…³æœ¬çš„å¯¦éš›ç”¨é€”"
            ]
            if len(lines) ==0:
                lines = [shebang] + new_header
            else:
                lines = [shebang] + new_header + lines[1:] if shebang == lines[0] else new_header + lines
            file_path.write_text("\n".join(lines), encoding="utf-8")
            comment_lines = [l.strip("# ").strip() for l in new_header]
            updated = True
        comment_lines = normalize_comments(comment_lines)

    else:
        return None
    start_folder = file_path.parent.parent.name
    parts = file_path.parts
    index = parts.index(start_folder)
    relative_path = Path(*parts[index:])
    return {
        "filename": filename,
        "filepath": str(relative_path),
        "comment1": comment_lines[0],
        "comment2": comment_lines[1],
        "comment3": comment_lines[2],
        "language": lang
    }

def scan_and_generate(base_dir: Path):
    results = []
    markdown_lines = ["# ğŸ“œ è…³æœ¬ç¸½è¦½ï¼ˆè‡ªå‹•ç”¢ç”Ÿï¼‰\n"]

    for ext in ("*.py", "*.sh"):
        for file in sorted(base_dir.rglob(ext)):
            if file.name == "analyze_scripts.py":
                continue
            info = extract_header(file)
            if info:
                results.append(info)
                markdown_lines.append(f"## {info['filename']}")
                markdown_lines.append(f"> {info['filepath']}")
                markdown_lines.append(f"> {info['comment1']}")
                markdown_lines.append(f"> {info['comment2']}")
                markdown_lines.append(f"> {info['comment3']}")
                markdown_lines.append(f"> {info['language']}")
                markdown_lines.append("")

    return results, markdown_lines

if __name__ == "__main__":
    # BASE_DIR = Path(".")
    BASE_DIR = Path(__file__).parent if __file__ else Path.cwd()
    JSON_PATH = BASE_DIR / "script_headers.json"
    MD_PATH = BASE_DIR / "script_index.md"

    header_data, md_lines = scan_and_generate(BASE_DIR)

    with open(JSON_PATH, "w", encoding="utf-8") as jf:
        json.dump(header_data, jf, ensure_ascii=False, indent=2)

    with open(MD_PATH, "w", encoding="utf-8") as mf:
        mf.write("\n".join(md_lines))

    print(f"âœ… JSON å·²å„²å­˜ï¼š{JSON_PATH}")
    print(f"âœ… Markdown å·²å„²å­˜ï¼š{MD_PATH}")
