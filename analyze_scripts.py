"""
analyze_scripts.py

åŠŸèƒ½ï¼šæƒææ‰€æœ‰ .py èˆ‡ .sh æª”æ¡ˆï¼Œè£œä¸Šç¼ºå¤±è¨»è§£ä¸¦è¼¸å‡º Markdown èˆ‡ JSON æ¸…å–®  
ç”¨é€”ï¼šé›†ä¸­ç®¡ç†è…³æœ¬æè¿°èˆ‡ç”¨é€”ï¼Œè¼”åŠ©ç¶­è­·èˆ‡æŸ¥é–±
"""

import os
import json
import re
from pathlib import Path

def normalize_comments(lines: list[str], total=3):
    """è£œé½Šè¨»è§£è¡Œæ•¸è‡³ total"""
    while len(lines) < total:
        lines.append("")
    return lines[:total]

def extract_header(file_path: Path):
    try:
        content = file_path.read_text(encoding="utf-8")
        lines = content.splitlines()

    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è®€å– {file_path}: {e}")
        return None

    suffix = file_path.suffix
    filename = file_path.name

    comment_lines = []
    updated = False

    if suffix == ".py":
        # æª¢æŸ¥æ˜¯å¦æœ‰ docstring æ ¼å¼çš„è¨»è§£ (PEP257)
        docstring_match = re.search(r'"""(.*?)"""', content, re.DOTALL)
        if docstring_match:
            # å¾ docstring æå–è¨»è§£
            docstring_content = docstring_match.group(1).strip()
            docstring_lines = [line.strip() for line in docstring_content.splitlines()]
            # ç§»é™¤ç©ºè¡Œ
            docstring_lines = [line for line in docstring_lines if line]
            comment_lines = docstring_lines
        else:
            # èˆŠçš„æ–¹å¼ï¼šå°‹æ‰¾ # é–‹é ­çš„è¨»è§£
            for line in lines[:5]:
                if line.strip().startswith("#"):
                    comment_lines.append(line.strip("# ").strip())
        
        comment_lines = normalize_comments(comment_lines)
        lang = "python"

    elif suffix == ".sh":
        lang = "bash"
        # é¦–å…ˆè™•ç† shebang è¡Œ
        start_index = 0
        if lines and lines[0].startswith("#!"):
            start_index = 1  # è·³é shebang è¡Œ
            
        # å¾ shebang è¡Œä¹‹å¾Œé–‹å§‹å°‹æ‰¾è¨»è§£
        for line in lines[start_index:start_index+10]:  # å¢åŠ æœç´¢ç¯„åœåˆ°10è¡Œ
            if line.strip().startswith("#") and not line.strip().startswith("#!"):
                comment_content = line.strip("# ").strip()
                if comment_content:  # ç¢ºä¿è¨»è§£è¡Œä¸æ˜¯ç©ºçš„
                    comment_lines.append(comment_content)
                    
        if len(comment_lines) < 3:
            print(f"ğŸ› ï¸  è£œä¸Šè¨»è§£ï¼š{filename}")
            shebang = "#!/usr/bin/env bash"  # ä½¿ç”¨æ›´å¯ç§»æ¤çš„ shebang
            if lines and lines[0].startswith("#!"):
                shebang = lines[0]
                
            new_header = [
                f"# {filename}",
                "# åŠŸèƒ½ï¼šè«‹è£œä¸Šè…³æœ¬çš„åŠŸèƒ½èªªæ˜",
                "# ç”¨é€”ï¼šè«‹è£œä¸Šè…³æœ¬çš„å¯¦éš›ç”¨é€”"
            ]
            
            if len(lines) == 0:
                lines = [shebang] + new_header
            else:
                if lines[0].startswith("#!"):
                    lines = [shebang] + new_header + lines[1:]
                else:
                    lines = [shebang] + new_header + lines
                    
            file_path.write_text("\n".join(lines), encoding="utf-8")
            comment_lines = [l.strip("# ").strip() for l in new_header]
            updated = True
            
        comment_lines = normalize_comments(comment_lines)

    else:
        return None
        
    # å˜—è©¦ç²å–ç›®éŒ„çµæ§‹
    try:
        start_folder = file_path.parent.parent.name
        parts = file_path.parts
        index = parts.index(start_folder)
        relative_path = Path(*parts[index:])
    except (ValueError, IndexError):
        # å¦‚æœç„¡æ³•æ‰¾åˆ°é æœŸçš„çˆ¶ç›®éŒ„çµæ§‹ï¼Œå°±ä½¿ç”¨ç›¸å°æ–¼ç•¶å‰ç›®éŒ„çš„è·¯å¾‘
        relative_path = file_path
        
    return {
        "filename": filename,
        "filepath": str(relative_path),
        "comment1": comment_lines[0],
        "comment2": comment_lines[1],
        "comment3": comment_lines[2],
        "language": lang
    }

def scan_and_generate(base_dir: Path):
    results = []
    markdown_lines = ["# ğŸ“œ è…³æœ¬ç¸½è¦½ï¼ˆè‡ªå‹•ç”¢ç”Ÿï¼‰\n"]

    for ext in ("*.py", "*.sh"):
        for file in sorted(base_dir.rglob(ext)):
            if file.name == "analyze_scripts.py":
                continue
            info = extract_header(file)
            if info:
                results.append(info)
                # æ”¹è¿› Markdown æ ¼å¼
                markdown_lines.append(f"## {info['filename']}")
                markdown_lines.append(f"**è·¯å¾‘:** `{info['filepath']}`")
                markdown_lines.append("")
                markdown_lines.append("**èªªæ˜:**")
                if info['comment1']:
                    markdown_lines.append(f"- {info['comment1']}")
                if info['comment2']:
                    markdown_lines.append(f"- {info['comment2']}")
                if info['comment3'] and info['comment3'].strip():
                    markdown_lines.append(f"- {info['comment3']}")
                markdown_lines.append("")
                markdown_lines.append(f"**èªè¨€:** `{info['language']}`")
                markdown_lines.append("")
                markdown_lines.append("---")
                markdown_lines.append("")

    return results, markdown_lines

if __name__ == "__main__":
    # BASE_DIR = Path(".")
    BASE_DIR = Path(__file__).parent if __file__ else Path.cwd()
    JSON_PATH = BASE_DIR / "script_headers.json"
    MD_PATH = BASE_DIR / "script_index.md"

    header_data, md_lines = scan_and_generate(BASE_DIR)

    with open(JSON_PATH, "w", encoding="utf-8") as jf:
        json.dump(header_data, jf, ensure_ascii=False, indent=2)

    with open(MD_PATH, "w", encoding="utf-8") as mf:
        mf.write("\n".join(md_lines))

    print(f"âœ… JSON å·²å„²å­˜ï¼š{JSON_PATH}")
    print(f"âœ… Markdown å·²å„²å­˜ï¼š{MD_PATH}")